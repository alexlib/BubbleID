{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80c0f18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import torch, detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo, structures\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f1d2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "615a69de",
   "metadata": {},
   "outputs": [],
   "source": [
    "extension=\"\"\n",
    "directory_path=f\"/mnt/share/zdrive/Christy/BoilingImages/128\"\n",
    "video_file=f\"/mnt/share/zdrive/Christy/BoilingImages/Boiling-128.avi\"\n",
    "# save locations (where files will be saved)\n",
    "file_path=f'./Saved_Data/bb-Boiling-{extension}.txt'\n",
    "output_file_path=f'./Saved_Data/bb-Boiling-output-{extension}.txt'\n",
    "vapor_file=f'./Saved_Data/vapor_{extension}.npy'\n",
    "vapor_base_file=f'./Saved_Data/vaporBase_bt-{extension}.npy'\n",
    "bubble_size_file=f'./Saved_Data/bubble_size_bt-{extension}.npy'\n",
    "bubind_file=f'./Saved_Data/bubind_{extension}.npy'\n",
    "frameind_file=f'./Saved_Data/frames_{extension}.npy'\n",
    "classind_file=f'./Saved_Data/class_{extension}.npy'\n",
    "bubclassind_file=f'./Saved_Data/bubclass_{extension}.npy'\n",
    "thres=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "027225b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[09/12 17:03:59 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    }
   ],
   "source": [
    "from detectron2.engine import DefaultTrainer\n",
    "# load model\n",
    "cfg = get_cfg()\n",
    "cfg.OUTPUT_DIR = \"./Models\"\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.DATALOADER.NUM_WORKERS = 2\n",
    "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "cfg.SOLVER.MAX_ITER = 1000    # 1000 iterations seems good enough for this dataset\n",
    "cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # Default is 512, using 256 for this dataset.\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0670d965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/BoilingImages/128/Img000000.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000001.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000002.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000003.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000004.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000005.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000006.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000007.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000008.jpg', '/mnt/share/zdrive/Christy/BoilingImages/128/Img000009.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Load Images \n",
    "import os\n",
    "import glob\n",
    "\n",
    "def get_image_paths(directory):\n",
    "    \"\"\"\n",
    "    Get a list of file paths for all image files in the specified directory and its subdirectories.\n",
    "\n",
    "    Args:\n",
    "    directory (str): The directory to search for image files.\n",
    "\n",
    "    Returns:\n",
    "    List[str]: A list of file paths for all image files found, sorted alphabetically.\n",
    "    \"\"\"\n",
    "    image_extensions = ['*.jpg']  # Add more extensions as needed\n",
    "\n",
    "    image_paths = []\n",
    "    for extension in image_extensions:\n",
    "        pattern = os.path.join(directory, '**', extension)\n",
    "        image_paths.extend(glob.glob(pattern, recursive=True))\n",
    "\n",
    "    return sorted(image_paths)  # Sort the list of image paths alphabetically\n",
    "\n",
    "\n",
    "\n",
    "#hf=60\n",
    "# Specify the directory you want to search for image files\n",
    "#directory_path=f\"/mnt/share/zdrive/Christy/Boiling-78/{hf}W\"\n",
    "\n",
    "# Get a list of image file paths sorted alphabetically\n",
    "image_paths = get_image_paths(directory_path)\n",
    "\n",
    "# Print the sorted list of image file paths\n",
    "print(image_paths[0:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c37f81",
   "metadata": {},
   "source": [
    "## Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da198ade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/82603 [00:00<?, ?it/s]/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "100%|███████████████████████████████████████████████████████████████| 82603/82603 [1:11:53<00:00, 19.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#image_paths_sub=image_paths[0:-2]\n",
    "image_paths_sub=image_paths[0:]\n",
    "from tqdm import tqdm\n",
    "Bounding_Box=np.empty((0,7))\n",
    "bubble_size=[]\n",
    "vapor=[]\n",
    "vapor_base=[]\n",
    "for i in tqdm(range(len(image_paths_sub))):\n",
    "#for i in [117,118,119]:    \n",
    "    new_im = cv2.imread(image_paths_sub[i])\n",
    "    outputs  = predictor(new_im)\n",
    "    box=outputs[\"instances\"].pred_boxes\n",
    "    box=box.tensor\n",
    "    box=box.cpu().tolist()\n",
    "    masks=outputs[\"instances\"].pred_masks.cpu()\n",
    "    scores=outputs[\"instances\"].scores\n",
    "    #scores=scores.tensor\n",
    "    scores=scores.cpu().tolist()\n",
    "    class_val=outputs[\"instances\"].pred_classes.cpu().tolist()\n",
    "    \n",
    "    converted_bounding_box=[]\n",
    "    for j in range(len(box)):\n",
    "        x1, y1, x2, y2 = box[j]\n",
    "        \n",
    "        #if y2 > 502 and y2<533 and x1>320 and x1<515:\n",
    "        #if y2 > 502 and y2<680 and x1>250 and x1<580:\n",
    "        if y2 > 0:\n",
    "\n",
    "            converted_bounding_box.append([x1,y1,x2,y2])\n",
    "        elif y2 > 502 and y2<533 and x2>320 and x2<515:\n",
    "        #elif y2 > 502 and y2<680 and x2>250 and x2<580:\n",
    "            converted_bounding_box.append([x1,y1,x2,y2])\n",
    "      \n",
    "    box=converted_bounding_box\n",
    "    box_data = [[i+1]+ box[j] +[scores[j]] +[class_val[j]] for j in range(len(box))]\n",
    "   \n",
    "    if len(box_data) !=0:\n",
    "        Bounding_Box=np.vstack([Bounding_Box, box_data])\n",
    "    else:\n",
    "        print('Error')\n",
    "        outputs=predictor(new_im)\n",
    "        box=outputs[\"instances\"].pred_boxes\n",
    "        box=box.tensor\n",
    "        box=box.cpu().tolist()\n",
    "        x1,y1,x2,y2=box[0]\n",
    "        box_data = [[i+1]+ box[j] +[scores[j]]+ [class_val[j]] for j in range(len(box))]\n",
    "        \n",
    "        Bounding_Box=np.vstack([Bounding_Box, box_data])\n",
    "        \n",
    "    masks=outputs['instances'].pred_masks.cpu()\n",
    "    scores=outputs['instances'].scores.cpu()\n",
    "    index_tensor=torch.tensor([k for k in range(len(masks))])\n",
    "    index_to_keep=index_tensor[scores>thres]\n",
    "    masks=torch.index_select(masks, 0, index_to_keep)\n",
    "    class_val=np.array(class_val)[index_to_keep]\n",
    "    combined_mask=torch.any(masks, axis=0)\n",
    "    vapor.append(torch.sum(combined_mask).item())\n",
    "    indexs=np.where(np.array(class_val)==0)[0]\n",
    "    masks_base=masks[indexs]\n",
    "    combined_mask=torch.any(masks_base, axis=0)\n",
    "    vapor_base.append(torch.sum(combined_mask).item())\n",
    "    pixel_count=torch.sum(masks, dim=(1,2)).numpy()\n",
    "    bubble_size.append(pixel_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8a77c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "np.save(vapor_file, vapor)\n",
    "np.save(vapor_base_file, vapor_base)\n",
    "np.save(bubble_size_file,bubble_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89dae22e",
   "metadata": {},
   "source": [
    "## Tracking Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bf6a1f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████████████████████████████████████████████████████████▉| 82602/82603 [1:07:47<00:00, 18.73it/s]\r",
      "100%|███████████████████████████████████████████████████████████████| 82603/82603 [1:07:47<00:00, 20.31it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    }
   ],
   "source": [
    "# Define the file path where you want to save the data\n",
    "#file_path = 'ocsort-78-120W-base.txt'\n",
    "#file_path=f'./bb-Boiling78-{hf}W-base.txt'\n",
    "# Open the file for writing\n",
    "with open(file_path, 'w') as file:\n",
    "    for sublist in Bounding_Box:\n",
    "        formatted_values = []\n",
    "        for value in sublist:\n",
    "            if isinstance(value, int):\n",
    "                formatted_values.append(f'{int(value)}')  # Format integers as strings\n",
    "            elif isinstance(value, float):\n",
    "                formatted_values.append(f'{value:.4f}')  # Format floats with 4 decimal places\n",
    "            else:\n",
    "                formatted_values.append(str(value))  # Keep other types as they are\n",
    "        \n",
    "        # Manually format the first and last elements as integers\n",
    "        formatted_values[0] = str(int(float(formatted_values[0])))\n",
    "        formatted_values[-1] = str(int(float(formatted_values[-1])))\n",
    "        # Join the formatted values with spaces\n",
    "        line = ','.join(formatted_values)\n",
    "        \n",
    "        # Write the line to the file and add a newline character\n",
    "        file.write(line + '\\n')\n",
    "\n",
    "# Confirmation message\n",
    "print(f'Data saved to {file_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a7b89a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import cv2\n",
    "import filterpy\n",
    "import torch\n",
    "import super_gradients as sg\n",
    "import matplotlib.pyplot as plt\n",
    "from ocsort import ocsort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cd6f950e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys    \n",
    "\n",
    "def get_color(number):\n",
    "    \"\"\" Converts an integer number to a color \"\"\"\n",
    "    # change these however you want to\n",
    "    hue = number*30 % 180\n",
    "    saturation = number*103 % 256\n",
    "    value = number*50 % 256\n",
    "\n",
    "    # expects normalized values\n",
    "    color = colorsys.hsv_to_rgb(hue/179, saturation/255, value/255)\n",
    "\n",
    "    return [int(c*255) for c in color]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52c8c6f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./SavedDataAEREG/bb-Boiling-Boiling-126.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cldunlap/Documents/JAP-Code/Revised/ocsort/ocsort.py:41: RuntimeWarning: invalid value encountered in sqrt\n",
      "  w = np.sqrt(x[2] * x[3])\n"
     ]
    }
   ],
   "source": [
    "tracker=ocsort.OCSort(det_thresh=thres, max_age=10, min_hits=20)\n",
    "img_info=(600,832)\n",
    "img_size=(600,832)\n",
    "boiling_test=78\n",
    "hf=120\n",
    "#cap=cv2.VideoCapture(f\"/mnt/share/zdrive/Hari/Bubble hydro acoustic analysis/B83_210_Bubble/Bubble/video.avi\")\n",
    "#cap=cv2.VideoCapture(f\"/mnt/share/zdrive/Christy/Boiling-{boiling_test}/{hf}W-full.avi\")\n",
    "cap=cv2.VideoCapture(video_file)\n",
    "\n",
    "\n",
    "if (cap.isOpened() == False):\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "frames=[]\n",
    "i=0\n",
    "counter, fps, elapsed=0,0,0\n",
    "frame_data={}\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        # Split the line into components\n",
    "        parts = line.strip().split(',')\n",
    "        \n",
    "        # Extract frame ID and data\n",
    "        frame_id = int(parts[0])\n",
    "        data = list(map(float, parts[1:-1]))\n",
    "        \n",
    "        \n",
    "        # Check if the frame ID is already in the dictionary\n",
    "        if frame_id not in frame_data:\n",
    "            frame_data[frame_id] = []\n",
    "        \n",
    "        # Append the data to the corresponding frame ID\n",
    "        frame_data[frame_id].append(data)\n",
    "\n",
    "with open(output_file_path, 'w') as file:\n",
    "    \n",
    "    while(cap.isOpened()):\n",
    "        ret, frame=cap.read()\n",
    "    \n",
    "        if ret==True:\n",
    "            # load data from previously configured text file that has\n",
    "            # bounding boxes. (x1,y1,x2,y2,c)\n",
    "            xyxyc=frame_data.get(i+1, [])\n",
    "            i+=1\n",
    "            tracks=tracker.update(np.array(xyxyc), img_info, img_size)\n",
    "            \n",
    "            for track in tracker.trackers:\n",
    "                \n",
    "                track_id=track.id\n",
    "                hits=track.hits\n",
    "                color=get_color(track_id*15)\n",
    "                x1,y1,x2,y2=np.round(track.get_state()).astype(int).squeeze()\n",
    "                '''\n",
    "                cv2.rectangle(frame, (x1,y1),(x2,y2), color, 2)\n",
    "                cv2.putText(frame, f\"{track_id}-{hits}\",\n",
    "                            (x1+10, y1-5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                            0.5,\n",
    "                            color,\n",
    "                            1,\n",
    "                            cv2.LINE_AA)\n",
    "                #frames.append(frame)\n",
    "                '''\n",
    "                file.write(f'{i},{track_id},{hits},{x1},{y1},{x2},{y2}\\n')\n",
    "        else:\n",
    "            break\n",
    "    cap.release()\n",
    "    del cap\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9ec5aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Function for computing iou\n",
    "def iou_batch(bboxes1, bboxes2):\n",
    "    \"\"\"\n",
    "    From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "    \"\"\"\n",
    "    bboxes2 = np.expand_dims(bboxes2, 0)\n",
    "    bboxes1 = np.expand_dims(bboxes1, 1)\n",
    "    \n",
    "    xx1 = np.maximum(bboxes1[..., 0], bboxes2[..., 0])\n",
    "    yy1 = np.maximum(bboxes1[..., 1], bboxes2[..., 1])\n",
    "    xx2 = np.minimum(bboxes1[..., 2], bboxes2[..., 2])\n",
    "    yy2 = np.minimum(bboxes1[..., 3], bboxes2[..., 3])\n",
    "    w = np.maximum(0., xx2 - xx1)\n",
    "    h = np.maximum(0., yy2 - yy1)\n",
    "    wh = w * h\n",
    "    o = wh / ((bboxes1[..., 2] - bboxes1[..., 0]) * (bboxes1[..., 3] - bboxes1[..., 1])                                      \n",
    "        + (bboxes2[..., 2] - bboxes2[..., 0]) * (bboxes2[..., 3] - bboxes2[..., 1]) - wh)                                              \n",
    "    return(o)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e24675f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "real_data=np.loadtxt(file_path, delimiter=\",\")\n",
    "real=real_data[real_data[:,-2]>=thres]\n",
    "real=np.round(real[:,0:-2]).astype(int)\n",
    "#del real_data\n",
    "pred_data=np.loadtxt(output_file_path,delimiter=\",\").astype(int)\n",
    "\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "my_dict = {}\n",
    "\n",
    "# Assign keys ranging from 1 to 10 using a for loop\n",
    "for i in range(1, real[-1][0]+1):\n",
    "    my_dict[i] = []\n",
    "\n",
    "for item in real:\n",
    "    key=item[0]\n",
    "    value=item[1:]\n",
    "    if my_dict[key] is []:\n",
    "        my_dict[key]=(list(value))\n",
    "    else:\n",
    "        my_dict[key].append(list(value))\n",
    "realg=[values for values in my_dict.values()]\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "my_dict = {}\n",
    "\n",
    "# Assign keys ranging from 1 to 10 using a for loop\n",
    "for i in range(1, real[-1][0]+1):\n",
    "    my_dict[i] = []\n",
    "\n",
    "for item in real:\n",
    "    key=item[0]\n",
    "    value=item[1]\n",
    "    if my_dict[key] is []:\n",
    "        my_dict[key]=((value))\n",
    "    else:\n",
    "        my_dict[key].append((value))\n",
    "realgG=[values for values in my_dict.values()]\n",
    "\n",
    "# Initialize an empty dictionary\n",
    "my_dict = {}\n",
    "\n",
    "# Assign keys ranging from 1 to 10 using a for loop\n",
    "for i in range(1, real[-1][0]+1):\n",
    "    my_dict[i] = []\n",
    "\n",
    "for item in pred_data:\n",
    "    key=item[0]\n",
    "    value=item[1:]\n",
    "    if my_dict[key] is []:\n",
    "        my_dict[key]=(list(value))\n",
    "    else:\n",
    "        my_dict[key].append(list(value))\n",
    "predg=[values for values in my_dict.values()]\n",
    "\n",
    "\n",
    "import copy\n",
    "values=copy.deepcopy(realg)\n",
    "tracks=copy.deepcopy(realgG)\n",
    "\n",
    "# given previous frame and current frame remove row that doesn't have \n",
    "\n",
    "for k in range(len(predg)-1):\n",
    "#for k in range(2):\n",
    "    if len(predg[k]) > 0 and len(predg[k+1]) >0: \n",
    "        frame1=predg[k]\n",
    "        frame2=predg[k+1]\n",
    "        vector1=np.array(frame2)[:,0].tolist()\n",
    "        vector2=np.array(frame1)[:,0].tolist()\n",
    "        result_vector = np.full(len(vector1), -1)\n",
    "        for i, val in enumerate(vector1):\n",
    "            if val in vector2:\n",
    "                result_vector[i] = vector2.index(val)\n",
    "        j=0\n",
    "        for i in range(len(result_vector)):\n",
    "            if result_vector[i] !=-1:\n",
    "                if frame2[i][1]!= frame1[result_vector[i]][1]:\n",
    "                    #print(k,j,i)\n",
    "                    tracks[k+1][j]=frame2[i][0]\n",
    "                    values[k+1][j][:]=frame2[i][2:]\n",
    "                    j+=1\n",
    "            if result_vector[i] == -1:\n",
    "\n",
    "                tracks[k+1][j]=frame2[i][0]\n",
    "                values[k+1][j][:]=frame2[i][2:]\n",
    "                j+=1\n",
    "\n",
    "# Tracks is of shape (frames, bb in real detection (basically removes tracks with no hits))\n",
    "tracks[0]=np.array(predg[0])[:,0].tolist()\n",
    "values[0]=np.array(predg[0])[:,2:].tolist()\n",
    "\n",
    "for i in range(len(values)):\n",
    "    if len(values[i]) >0:\n",
    "        sort=np.argmax(iou_batch(realg[i],values[i]),axis=1).tolist()\n",
    "        tracks[i]=np.array(tracks[i])[sort].tolist()\n",
    "        \n",
    "        \n",
    "# Original data\n",
    "data = tracks\n",
    "\n",
    "# Find the maximum number in the original data\n",
    "#max_number = max(max(row) for row in data)\n",
    "max_number = max(max(sublist, default=float('-inf')) for sublist in data if sublist)\n",
    "\n",
    "# Create a list of lists to store the index positions and initial row numbers\n",
    "frames = [[] for _ in range(max_number + 1)]\n",
    "\n",
    "# Iterate through the original data and populate the result list\n",
    "for initial_row, row in enumerate(data):\n",
    "    for index, number in enumerate(row):\n",
    "        frames[number].append(initial_row)\n",
    "\n",
    "# Print the result with initial row numbers\n",
    "print(frames[0])\n",
    "\n",
    "\n",
    "# Original data\n",
    "data = tracks\n",
    "# Find the maximum number in the original data\n",
    "#max_number = max(max(row) for row in data)\n",
    "max_number = max(max(sublist, default=float('-inf')) for sublist in data if sublist)\n",
    "\n",
    "\n",
    "# Create a list of lists to store the index positions\n",
    "bubInd= [[] for _ in range(max_number + 1)]\n",
    "\n",
    "# Iterate through the original data and populate the result list\n",
    "for row in data:\n",
    "    for index, number in enumerate(row):\n",
    "        bubInd[number].append(index)\n",
    "\n",
    "# Print the result\n",
    "#print(bubInd)\n",
    "\n",
    "# Save Data\n",
    "bubInd=np.array(bubInd, dtype=object)\n",
    "np.save(bubind_file, bubInd)\n",
    "frames=np.array(frames, dtype=object)\n",
    "np.save(frameind_file, frames)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
