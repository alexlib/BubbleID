{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57550326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries:\n",
    "import torch, detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo, structures\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526eda63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ninput_tensor = transform(Image.fromarray(combined_image)).unsqueeze(0)\\n\\nmodel.eval()\\nwith torch.no_grad():\\n    outputs=model(input_tensor)\\n    \\n_, predicted=torch.max(outputs,1)\\n\\nprint(predicted.item())\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "import os\n",
    "import torch\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Define CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=6, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=6, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 * 7 * 7, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "model = CNN()\n",
    "model.load_state_dict(torch.load('best_model_weights.pth'))\n",
    "\n",
    "\n",
    "# Load and preprocess the unseen image\n",
    "#image_path = './output/test/detached/Img041979_bt83-15W_mask_8.png'  # Replace with the path to your image\n",
    "#image = Image.open(image_path)\n",
    "transform = transforms.Compose([\n",
    "        #transforms.Resize(256),\n",
    "        transforms.Resize((480,640)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "'''\n",
    "input_tensor = transform(Image.fromarray(combined_image)).unsqueeze(0)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs=model(input_tensor)\n",
    "    \n",
    "_, predicted=torch.max(outputs,1)\n",
    "\n",
    "print(predicted.item())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d09fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfs=[15,30,45,60,75,90,105,120,135,150,165,180,195,214,235]\n",
    "extensions=[f\"Boiling-114-{hf}W\" for hf in hfs]\n",
    "directory_paths=[f\"/mnt/share/zdrive/Christy/Boiling-114/{hf}W\" for hf in hfs]\n",
    "video_files=[f\"/mnt/share/zdrive/Christy/JAP-Revised-Videos/DepartureRates/114/{hf}W-0.avi\" for hf in hfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b8cd96a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[04/24 10:35:57 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 10:35:57] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/15W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/15W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 2001/2001 [1:41:17<00:00,  3.04s/it]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-15W.txt\n",
      "[0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 47]\n",
      "\u001b[32m[04/24 12:17:48 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 12:17:48] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/30W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/30W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [45:21<00:00,  1.36s/it]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-30W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59]\n",
      "\u001b[32m[04/24 13:03:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 13:03:37] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/45W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/45W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [38:21<00:00,  1.15s/it]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-45W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n",
      "\u001b[32m[04/24 13:42:24 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 13:42:24] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/60W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/60W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [38:50<00:00,  1.16s/it]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-60W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 264, 266, 267, 268, 269, 270, 271, 272, 273, 274]\n",
      "\u001b[32m[04/24 14:21:44 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 14:21:44] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/75W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/75W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [27:21<00:00,  1.22it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-75W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 340, 341, 342, 343, 347, 348, 349, 350, 351, 352, 353, 356, 357, 358, 359, 360, 361, 362]\n",
      "\u001b[32m[04/24 14:49:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 14:49:37] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/90W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/90W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [22:40<00:00,  1.47it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-90W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 187]\n",
      "\u001b[32m[04/24 15:12:38 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 15:12:38] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/105W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/105W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [25:35<00:00,  1.30it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-105W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55]\n",
      "\u001b[32m[04/24 15:38:40 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 15:38:40] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/120W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/120W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [24:01<00:00,  1.39it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-120W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 73, 75, 76, 79, 80, 83, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 137, 141, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160]\n",
      "\u001b[32m[04/24 16:03:08 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 16:03:08] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/135W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/135W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [24:11<00:00,  1.38it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-135W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161]\n",
      "\u001b[32m[04/24 16:27:45 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 16:27:45] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/150W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/150W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [26:00<00:00,  1.28it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-150W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
      "\u001b[32m[04/24 16:54:13 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 16:54:13] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/165W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/165W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [21:16<00:00,  1.57it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-165W.txt\n",
      "[0, 1, 5, 6, 7, 9, 10, 11, 12, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 69, 70, 71, 72, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444]\n",
      "\u001b[32m[04/24 17:15:56 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 17:15:56] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/180W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/180W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [21:11<00:00,  1.57it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-180W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 128, 129, 130, 132, 133, 134, 135, 136, 137]\n",
      "\u001b[32m[04/24 17:37:32 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 17:37:32] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/195W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/195W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [20:54<00:00,  1.60it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-195W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 64, 67, 69, 70]\n",
      "\u001b[32m[04/24 17:58:52 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 17:58:52] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/214W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/214W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [20:19<00:00,  1.64it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-214W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 153, 158, 160, 161, 167, 172, 174, 176, 177, 178, 179, 183, 184, 186, 187, 188, 191, 192, 193, 197, 198, 199, 200, 206, 214, 215, 218, 220, 222, 223, 224, 225, 227, 228, 229, 230, 233, 239, 240, 241, 242, 243, 244, 248, 253]\n",
      "\u001b[32m[04/24 18:19:37 d2.checkpoint.detection_checkpoint]: \u001b[0m[DetectionCheckpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-24 18:19:37] INFO - checkpoint.py - [Checkpointer] Loading from ./Models/model_final.pth ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/mnt/share/zdrive/Christy/Boiling-114/235W/Img000000.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000001.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000002.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000003.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000004.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000005.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000006.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000007.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000008.jpg', '/mnt/share/zdrive/Christy/Boiling-114/235W/Img000009.jpg']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2001/2001 [20:19<00:00,  1.64it/s]\n",
      "/home/cldunlap/.conda/envs/detectron2_4/lib/python3.8/site-packages/numpy/lib/npyio.py:518: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  arr = np.asanyarray(arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to ./Saved_Data1/bb-Boiling-Boiling-114-235W.txt\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 43]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for indx in range(len(extensions)):\n",
    "    extension=extensions[indx] \n",
    "    directory_path=directory_paths[indx]\n",
    "    video_file=video_files[indx]\n",
    "\n",
    "\n",
    "    # save locations\n",
    "    file_path=f'./Saved_Data1/bb-Boiling-{extension}.txt'\n",
    "    output_file_path=f'./Saved_Data1/bb-Boiling-output-{extension}.txt'\n",
    "    vapor_file=f'./Saved_Data1/vapor_{extension}.npy'\n",
    "    vapor_base_file=f'./Saved_Data1/vaporBase_bt-{extension}.npy'\n",
    "    bubble_size_file=f'./Saved_Data1/bubble_size_bt-{extension}.npy'\n",
    "    bubind_file=f'./Saved_Data1/bubind_{extension}.npy'\n",
    "    frameind_file=f'./Saved_Data1/frames_{extension}.npy'\n",
    "    classind_file=f'./Saved_Data1/class_{extension}.npy'\n",
    "    bubclassind_file=f'./Saved_Data1/bubclass_{extension}.npy'\n",
    "    thres=0.9\n",
    "\n",
    "    import torch\n",
    "    torch.cuda.is_available()\n",
    "\n",
    "    from detectron2.engine import DefaultTrainer\n",
    "    # load model\n",
    "    cfg = get_cfg()\n",
    "    cfg.OUTPUT_DIR = \"./Models\"\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "    cfg.DATALOADER.NUM_WORKERS = 2\n",
    "    cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # Let training initialize from model zoo\n",
    "    cfg.SOLVER.IMS_PER_BATCH = 2  # This is the real \"batch size\" commonly known to deep learning people\n",
    "    cfg.SOLVER.BASE_LR = 0.00025  # pick a good LR\n",
    "    cfg.SOLVER.MAX_ITER = 1000    # 1000 iterations seems good enough for this dataset\n",
    "    cfg.SOLVER.STEPS = []        # do not decay learning rate\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 256   # Default is 512, using 256 for this dataset.\n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "    cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")  # path to the model we just trained\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5   # set a custom testing threshold\n",
    "    predictor = DefaultPredictor(cfg)\n",
    "\n",
    "    # Load Images \n",
    "    import os\n",
    "    import glob\n",
    "\n",
    "    def get_image_paths(directory):\n",
    "        \"\"\"\n",
    "        Get a list of file paths for all image files in the specified directory and its subdirectories.\n",
    "\n",
    "        Args:\n",
    "        directory (str): The directory to search for image files.\n",
    "\n",
    "        Returns:\n",
    "        List[str]: A list of file paths for all image files found, sorted alphabetically.\n",
    "        \"\"\"\n",
    "        image_extensions = ['*.jpg']  # Add more extensions as needed\n",
    "\n",
    "        image_paths = []\n",
    "        for extension in image_extensions:\n",
    "            pattern = os.path.join(directory, '**', extension)\n",
    "            image_paths.extend(glob.glob(pattern, recursive=True))\n",
    "\n",
    "        return sorted(image_paths)  # Sort the list of image paths alphabetically\n",
    "\n",
    "\n",
    "\n",
    "    #hf=60\n",
    "    # Specify the directory you want to search for image files\n",
    "    #directory_path=f\"/mnt/share/zdrive/Christy/Boiling-78/{hf}W\"\n",
    "\n",
    "    # Get a list of image file paths sorted alphabetically\n",
    "    image_paths = get_image_paths(directory_path)\n",
    "\n",
    "    # Print the sorted list of image file paths\n",
    "    print(image_paths[0:10])\n",
    "\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    image_paths_sub=image_paths[0:2001]\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    Bounding_Box=np.empty((0,7))\n",
    "    bubble_size=[]\n",
    "    vapor=[]\n",
    "    vapor_base=[]\n",
    "    for i in tqdm(range(len(image_paths_sub))):\n",
    "    #for i in [117,118,119]:    \n",
    "        new_im = cv2.imread(image_paths_sub[i])\n",
    "        outputs  = predictor(new_im)\n",
    "        box=outputs[\"instances\"].pred_boxes\n",
    "        box=box.tensor\n",
    "        box=box.cpu().tolist()\n",
    "        masks=outputs[\"instances\"].pred_masks.cpu()\n",
    "        scores=outputs[\"instances\"].scores\n",
    "        #scores=scores.tensor\n",
    "        scores=scores.cpu().tolist()\n",
    "        new_im = cv2.cvtColor(new_im, cv2.COLOR_BGR2GRAY)\n",
    "        new_im = new_im.reshape((new_im.shape[0],new_im.shape[1], 1))\n",
    "        class_val=[]\n",
    "        for k in range(len(outputs['instances'].pred_masks)):\n",
    "            if outputs['instances'].scores[k] > 0:\n",
    "                mask=outputs['instances'].pred_masks[k].cpu()\n",
    "                mask=np.reshape(np.array(mask, dtype=np.uint8), (mask.shape[0], mask.shape[1],1))    \n",
    "\n",
    "                object_image1 = np.zeros_like(new_im)\n",
    "                object_image1[mask > 0] = new_im[mask > 0]\n",
    "\n",
    "                object_image2 = np.zeros_like(new_im)\n",
    "                object_image2[mask <= 0] = new_im[mask <= 0]\n",
    "\n",
    "                mask = np.where(mask == 0, 0, 255).astype(np.uint8)\n",
    "\n",
    "                combined_image = np.concatenate((mask, object_image1, object_image2), axis=2)\n",
    "                mask_filename=f'./mask.png'\n",
    "                cv2.imwrite(mask_filename, combined_image)\n",
    "\n",
    "                input_tensor = transform(Image.open('./mask.png')).unsqueeze(0)\n",
    "\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    output=model(input_tensor)\n",
    "\n",
    "                _, predicted=torch.max(output,1)\n",
    "\n",
    "                class_val.append(predicted.item())\n",
    "                \n",
    "                # Map the predicted class to the class name\n",
    "        class_val=np.array(class_val)\n",
    "        \n",
    "        \n",
    "        converted_bounding_box=[]\n",
    "        for j in range(len(box)):\n",
    "            x1, y1, x2, y2 = box[j]\n",
    "\n",
    "            #if y2 > 502 and y2<533 and x1>320 and x1<515:\n",
    "            #if y2 > 502 and y2<680 and x1>250 and x1<580:\n",
    "            if y2 > 0:\n",
    "\n",
    "                converted_bounding_box.append([x1,y1,x2,y2])\n",
    "            elif y2 > 502 and y2<533 and x2>320 and x2<515:\n",
    "            #elif y2 > 502 and y2<680 and x2>250 and x2<580:\n",
    "                converted_bounding_box.append([x1,y1,x2,y2])\n",
    "\n",
    "        box=converted_bounding_box\n",
    "        box_data = [[i+1]+ box[j] +[scores[j]] +[class_val[j]] for j in range(len(box))]\n",
    "\n",
    "        if len(box_data) !=0:\n",
    "            Bounding_Box=np.vstack([Bounding_Box, box_data])\n",
    "        else:\n",
    "            print('Error')\n",
    "            outputs=predictor(new_im)\n",
    "            box=outputs[\"instances\"].pred_boxes\n",
    "            box=box.tensor\n",
    "            box=box.cpu().tolist()\n",
    "            x1,y1,x2,y2=box[0]\n",
    "            box_data = [[i+1]+ box[j] +[scores[j]]+ [class_val[j]] for j in range(len(box))]\n",
    "\n",
    "            Bounding_Box=np.vstack([Bounding_Box, box_data])\n",
    "\n",
    "        masks=outputs['instances'].pred_masks.cpu()\n",
    "        scores=outputs['instances'].scores.cpu()\n",
    "        index_tensor=torch.tensor([k for k in range(len(masks))])\n",
    "        index_to_keep=index_tensor[scores>thres]\n",
    "        masks=torch.index_select(masks, 0, index_to_keep)\n",
    "        \n",
    "        class_val=np.array(class_val)[index_to_keep]\n",
    "\n",
    "        combined_mask=torch.any(masks, axis=0)\n",
    "        vapor.append(torch.sum(combined_mask).item())\n",
    "        indexs=np.where(np.array(class_val)==0)[0]\n",
    "        masks_base=masks[indexs]\n",
    "        combined_mask=torch.any(masks_base, axis=0)\n",
    "        vapor_base.append(torch.sum(combined_mask).item())\n",
    "        pixel_count=torch.sum(masks, dim=(1,2)).numpy()\n",
    "        bubble_size.append(pixel_count)\n",
    "\n",
    "    np.save(vapor_file, vapor)\n",
    "    np.save(vapor_base_file, vapor_base)\n",
    "    np.save(bubble_size_file,bubble_size)\n",
    "\n",
    "    # Define the file path where you want to save the data\n",
    "    #file_path = 'ocsort-78-120W-base.txt'\n",
    "    #file_path=f'./bb-Boiling78-{hf}W-base.txt'\n",
    "    # Open the file for writing\n",
    "    with open(file_path, 'w') as file:\n",
    "        for sublist in Bounding_Box:\n",
    "            formatted_values = []\n",
    "            for value in sublist:\n",
    "                if isinstance(value, int):\n",
    "                    formatted_values.append(f'{int(value)}')  # Format integers as strings\n",
    "                elif isinstance(value, float):\n",
    "                    formatted_values.append(f'{value:.4f}')  # Format floats with 4 decimal places\n",
    "                else:\n",
    "                    formatted_values.append(str(value))  # Keep other types as they are\n",
    "\n",
    "            # Manually format the first and last elements as integers\n",
    "            formatted_values[0] = str(int(float(formatted_values[0])))\n",
    "            formatted_values[-1] = str(int(float(formatted_values[-1])))\n",
    "            # Join the formatted values with spaces\n",
    "            line = ','.join(formatted_values)\n",
    "\n",
    "            # Write the line to the file and add a newline character\n",
    "            file.write(line + '\\n')\n",
    "\n",
    "    # Confirmation message\n",
    "    print(f'Data saved to {file_path}')\n",
    "\n",
    "    # Import libraries\n",
    "\n",
    "    import os\n",
    "    import time\n",
    "    from tqdm import tqdm\n",
    "    import numpy as np\n",
    "    import cv2\n",
    "    import filterpy\n",
    "    import torch\n",
    "    import super_gradients as sg\n",
    "    import matplotlib.pyplot as plt\n",
    "    from ocsort import ocsort\n",
    "\n",
    "    import colorsys    \n",
    "\n",
    "    def get_color(number):\n",
    "        \"\"\" Converts an integer number to a color \"\"\"\n",
    "        # change these however you want to\n",
    "        hue = number*30 % 180\n",
    "        saturation = number*103 % 256\n",
    "        value = number*50 % 256\n",
    "\n",
    "        # expects normalized values\n",
    "        color = colorsys.hsv_to_rgb(hue/179, saturation/255, value/255)\n",
    "\n",
    "        return [int(c*255) for c in color]\n",
    "\n",
    "    tracker=ocsort.OCSort(det_thresh=thres, max_age=10, min_hits=20)\n",
    "    img_info=(600,832)\n",
    "    img_size=(600,832)\n",
    "    boiling_test=78\n",
    "    hf=120\n",
    "    #cap=cv2.VideoCapture(f\"/mnt/share/zdrive/Hari/Bubble hydro acoustic analysis/B83_210_Bubble/Bubble/video.avi\")\n",
    "    #cap=cv2.VideoCapture(f\"/mnt/share/zdrive/Christy/Boiling-{boiling_test}/{hf}W-full.avi\")\n",
    "    cap=cv2.VideoCapture(video_file)\n",
    "\n",
    "\n",
    "    if (cap.isOpened() == False):\n",
    "        print(\"Error opening video file\")\n",
    "\n",
    "    frames=[]\n",
    "    i=0\n",
    "    counter, fps, elapsed=0,0,0\n",
    "    frame_data={}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Split the line into components\n",
    "            parts = line.strip().split(',')\n",
    "\n",
    "            # Extract frame ID and data\n",
    "            frame_id = int(parts[0])\n",
    "            data = list(map(float, parts[1:-1]))\n",
    "\n",
    "\n",
    "            # Check if the frame ID is already in the dictionary\n",
    "            if frame_id not in frame_data:\n",
    "                frame_data[frame_id] = []\n",
    "\n",
    "            # Append the data to the corresponding frame ID\n",
    "            frame_data[frame_id].append(data)\n",
    "\n",
    "    with open(output_file_path, 'w') as file:\n",
    "\n",
    "        while(cap.isOpened()):\n",
    "            ret, frame=cap.read()\n",
    "\n",
    "            if ret==True:\n",
    "                # load data from previously configured text file that has\n",
    "                # bounding boxes. (x1,y1,x2,y2,c)\n",
    "                xyxyc=frame_data.get(i+1, [])\n",
    "                i+=1\n",
    "                tracks=tracker.update(np.array(xyxyc), img_info, img_size)\n",
    "\n",
    "                for track in tracker.trackers:\n",
    "\n",
    "                    track_id=track.id\n",
    "                    hits=track.hits\n",
    "                    color=get_color(track_id*15)\n",
    "                    x1,y1,x2,y2=np.round(track.get_state()).astype(int).squeeze()\n",
    "                    '''\n",
    "                    cv2.rectangle(frame, (x1,y1),(x2,y2), color, 2)\n",
    "                    cv2.putText(frame, f\"{track_id}-{hits}\",\n",
    "                                (x1+10, y1-5),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                                0.5,\n",
    "                                color,\n",
    "                                1,\n",
    "                                cv2.LINE_AA)\n",
    "                    #frames.append(frame)\n",
    "                    '''\n",
    "                    file.write(f'{i},{track_id},{hits},{x1},{y1},{x2},{y2}\\n')\n",
    "            else:\n",
    "                break\n",
    "        cap.release()\n",
    "        del cap\n",
    "\n",
    "    # Define Function for computing iou\n",
    "    def iou_batch(bboxes1, bboxes2):\n",
    "        \"\"\"\n",
    "        From SORT: Computes IOU between two bboxes in the form [x1,y1,x2,y2]\n",
    "        \"\"\"\n",
    "        bboxes2 = np.expand_dims(bboxes2, 0)\n",
    "        bboxes1 = np.expand_dims(bboxes1, 1)\n",
    "\n",
    "        xx1 = np.maximum(bboxes1[..., 0], bboxes2[..., 0])\n",
    "        yy1 = np.maximum(bboxes1[..., 1], bboxes2[..., 1])\n",
    "        xx2 = np.minimum(bboxes1[..., 2], bboxes2[..., 2])\n",
    "        yy2 = np.minimum(bboxes1[..., 3], bboxes2[..., 3])\n",
    "        w = np.maximum(0., xx2 - xx1)\n",
    "        h = np.maximum(0., yy2 - yy1)\n",
    "        wh = w * h\n",
    "        o = wh / ((bboxes1[..., 2] - bboxes1[..., 0]) * (bboxes1[..., 3] - bboxes1[..., 1])                                      \n",
    "            + (bboxes2[..., 2] - bboxes2[..., 0]) * (bboxes2[..., 3] - bboxes2[..., 1]) - wh)                                              \n",
    "        return(o)  \n",
    "\n",
    "    # load data\n",
    "    real_data=np.loadtxt(file_path, delimiter=\",\")\n",
    "    real=real_data[real_data[:,-2]>=thres]\n",
    "    real=np.round(real[:,0:-2]).astype(int)\n",
    "    #del real_data\n",
    "    pred_data=np.loadtxt(output_file_path,delimiter=\",\").astype(int)\n",
    "\n",
    "\n",
    "    # Initialize an empty dictionary\n",
    "    my_dict = {}\n",
    "\n",
    "    # Assign keys ranging from 1 to 10 using a for loop\n",
    "    for i in range(1, real[-1][0]+1):\n",
    "        my_dict[i] = []\n",
    "\n",
    "    for item in real:\n",
    "        key=item[0]\n",
    "        value=item[1:]\n",
    "        if my_dict[key] is []:\n",
    "            my_dict[key]=(list(value))\n",
    "        else:\n",
    "            my_dict[key].append(list(value))\n",
    "    realg=[values for values in my_dict.values()]\n",
    "\n",
    "    # Initialize an empty dictionary\n",
    "    my_dict = {}\n",
    "\n",
    "    # Assign keys ranging from 1 to 10 using a for loop\n",
    "    for i in range(1, real[-1][0]+1):\n",
    "        my_dict[i] = []\n",
    "\n",
    "    for item in real:\n",
    "        key=item[0]\n",
    "        value=item[1]\n",
    "        if my_dict[key] is []:\n",
    "            my_dict[key]=((value))\n",
    "        else:\n",
    "            my_dict[key].append((value))\n",
    "    realgG=[values for values in my_dict.values()]\n",
    "\n",
    "    # Initialize an empty dictionary\n",
    "    my_dict = {}\n",
    "\n",
    "    # Assign keys ranging from 1 to 10 using a for loop\n",
    "    for i in range(1, real[-1][0]+1):\n",
    "        my_dict[i] = []\n",
    "\n",
    "    for item in pred_data:\n",
    "        key=item[0]\n",
    "        value=item[1:]\n",
    "        if my_dict[key] is []:\n",
    "            my_dict[key]=(list(value))\n",
    "        else:\n",
    "            my_dict[key].append(list(value))\n",
    "    predg=[values for values in my_dict.values()]\n",
    "\n",
    "\n",
    "    import copy\n",
    "    values=copy.deepcopy(realg)\n",
    "    tracks=copy.deepcopy(realgG)\n",
    "\n",
    "    # given previous frame and current frame remove row that doesn't have \n",
    "\n",
    "    for k in range(len(predg)-1):\n",
    "    #for k in range(2):\n",
    "        if len(predg[k]) > 0 and len(predg[k+1]) >0: \n",
    "            frame1=predg[k]\n",
    "            frame2=predg[k+1]\n",
    "            vector1=np.array(frame2)[:,0].tolist()\n",
    "            vector2=np.array(frame1)[:,0].tolist()\n",
    "            result_vector = np.full(len(vector1), -1)\n",
    "            for i, val in enumerate(vector1):\n",
    "                if val in vector2:\n",
    "                    result_vector[i] = vector2.index(val)\n",
    "            j=0\n",
    "            for i in range(len(result_vector)):\n",
    "                if result_vector[i] !=-1:\n",
    "                    if frame2[i][1]!= frame1[result_vector[i]][1]:\n",
    "                        #print(k,j,i)\n",
    "                        tracks[k+1][j]=frame2[i][0]\n",
    "                        values[k+1][j][:]=frame2[i][2:]\n",
    "                        j+=1\n",
    "                if result_vector[i] == -1:\n",
    "\n",
    "                    tracks[k+1][j]=frame2[i][0]\n",
    "                    values[k+1][j][:]=frame2[i][2:]\n",
    "                    j+=1\n",
    "\n",
    "    # Tracks is of shape (frames, bb in real detection (basically removes tracks with no hits))\n",
    "    tracks[0]=np.array(predg[0])[:,0].tolist()\n",
    "    values[0]=np.array(predg[0])[:,2:].tolist()\n",
    "\n",
    "    for i in range(len(values)):\n",
    "        if len(values[i]) >0:\n",
    "            sort=np.argmax(iou_batch(realg[i],values[i]),axis=1).tolist()\n",
    "            tracks[i]=np.array(tracks[i])[sort].tolist()\n",
    "\n",
    "\n",
    "    # Original data\n",
    "    data = tracks\n",
    "\n",
    "    # Find the maximum number in the original data\n",
    "    #max_number = max(max(row) for row in data)\n",
    "    max_number = max(max(sublist, default=float('-inf')) for sublist in data if sublist)\n",
    "\n",
    "    # Create a list of lists to store the index positions and initial row numbers\n",
    "    frames = [[] for _ in range(max_number + 1)]\n",
    "\n",
    "    # Iterate through the original data and populate the result list\n",
    "    for initial_row, row in enumerate(data):\n",
    "        for index, number in enumerate(row):\n",
    "            frames[number].append(initial_row)\n",
    "\n",
    "    # Print the result with initial row numbers\n",
    "    print(frames[0])\n",
    "\n",
    "\n",
    "    # Original data\n",
    "    data = tracks\n",
    "    # Find the maximum number in the original data\n",
    "    #max_number = max(max(row) for row in data)\n",
    "    max_number = max(max(sublist, default=float('-inf')) for sublist in data if sublist)\n",
    "\n",
    "\n",
    "    # Create a list of lists to store the index positions\n",
    "    bubInd= [[] for _ in range(max_number + 1)]\n",
    "\n",
    "    # Iterate through the original data and populate the result list\n",
    "    for row in data:\n",
    "        for index, number in enumerate(row):\n",
    "            bubInd[number].append(index)\n",
    "\n",
    "    # Print the result\n",
    "    #print(bubInd)\n",
    "\n",
    "    # Save Data\n",
    "    bubInd=np.array(bubInd, dtype=object)\n",
    "    np.save(bubind_file, bubInd)\n",
    "    frames=np.array(frames, dtype=object)\n",
    "    np.save(frameind_file, frames)\n",
    "\n",
    "\n",
    "\n",
    "    classes=real_data[:,-1]\n",
    "\n",
    "    # Initialize an empty dictionary\n",
    "    my_dict = {}\n",
    "\n",
    "    # Assign keys ranging from 1 to 10 using a for loop\n",
    "    for i in range(1, real[-1][0]+1):\n",
    "        my_dict[i] = []\n",
    "\n",
    "    for item in real_data:\n",
    "        key=item[0]\n",
    "        value=item[-1]\n",
    "        if my_dict[key] is []:\n",
    "            my_dict[key]=((value))\n",
    "        else:\n",
    "            my_dict[key].append((value))\n",
    "    realgG=[values for values in my_dict.values()]\n",
    "\n",
    "    np.save(classind_file,realgG)\n",
    "\n",
    "    bub_class=copy.deepcopy(frames)\n",
    "    for j in range(len(bubInd)):\n",
    "        bub=j\n",
    "        for i in range(len(frames[bub])):\n",
    "            bub_class[j][i]=realgG[frames[bub][i]][bubInd[bub][i]]\n",
    "\n",
    "\n",
    "    bub_class=np.array(bub_class, dtype=object)\n",
    "    np.save(bubclassind_file, bub_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc814eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.        , 257.11065674, 133.36230469, 624.76635742,\n",
       "       532.40148926,   0.97969669,   0.        ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 1327]\n"
     ]
    }
   ],
   "source": [
    "Bounding_Box[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d216d2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
